#!/usr/bin/python
import requests, time, sys
from lxml import html


class Webpage:
    # Private Functions
    def __init__( self, url=None ):
        if url is None:
            self.tree = None
            self.page = None
        else:
            self._loadWebpage(url)

    def _loadWebpage(self, url):
        headers = {
            'User-Agent': 'My User Agent 1.0',
            'From': 'youremail@domain.com'  # This is another valid field
        }
        cookie = dict(over18="1")
        print("Getting webpage: " + url)
        timedelay = 0
        while( True ):
            if hasattr(self, "page"):
                prevpage = self.page
            time.sleep( timedelay )
            try:
                self.page = requests.get( url, headers=headers, cookies=cookie )
            except ConnectionError:
                time.sleep( 10 )
                self.page = requests.get( url, headers=headers, cookies=cookie )
                if(self.page == prevpage):
                    print('Page failed to load. URL: ' + url)
                    self.page = None
                    self.tree = None
                    return 0
            self.tree = html.fromstring( self.page.content )
            if( self.page.status_code != 429 and self.page.status_code != 404 and self.page.status_code != 503):
                prevpage = self.page
                return 1
            elif( self.page.status_code == 404 ):
                print('Page gives error 404. URL: ' + url)
                return 0
            elif( self.page.status_code == 503):
                print("Website Returned Error 503: Waiting 30 seconds.")
                timedelay *= 20
            else:
                timedelay *= 20
                print("Website Returned Error " + str(self.page.status_code) + ": Waiting " + str(timedelay) + " seconds.")


# Download All Pictures
link = str(sys.argv[1])
comic = Webpage(link)

title = comic.tree.xpath('//div[@id="info"]/h1/text()')[0]
subtitle = comic.tree.xpath('//div[@id="info"]/h2/text()')[0]
artist = []
group = []
parody = []
language = []
tags = []

with open('info', 'w+') as f:
    f.write(
        link + "\n" + title + "\n" +
        subtitle + "\n" + str(artist) + "\n" +
        str(group) + "\n" + str(parody) + "\n" +
        str(language) + "\n" + str(tags) + "\n"
    )

total_num_pages = int( comic.tree.xpath('//div[@id="info"]/div')[0].text_content().split(" ")[0] )

comic_page = Webpage("https://nhentai.net" + comic.tree.xpath('//a[@class="gallerythumb"]/@href')[0])
img_link = comic_page.tree.xpath('//section[@id="image-container"]/a/img')[0].attrib["src"]
img_link_components = img_link.split("/")
img_link_components_ext = img_link_components[-1].split(".")[-1]
img_link_components_page_num = int(img_link_components[-1].split(".")[0])
with open('page_links', 'w') as f:
    for i in range(total_num_pages):
        f.write(img_link + "\n")

        img_link_components_page_num += 1
        img_link_components[-1] = str( img_link_components_page_num ) + "." + img_link_components_ext
        img_link = "/".join( img_link_components )
